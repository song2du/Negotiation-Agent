import streamlit as st
from langchain_core.messages import HumanMessage, AIMessage
from core.scenarios import PRIORITIES

def render_messages(chat_placeholder):
    with chat_placeholder.container():
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"], avatar=msg.get("avatar")):
                st.markdown(msg["content"])

def normalize_text(text):
    """í…ìŠ¤íŠ¸ ë¹„êµë¥¼ ìœ„í•œ ì •ê·œí™” í—¬í¼ í•¨ìˆ˜"""
    if not text: return ""
    return "".join(text.split())

def process_graph_stream(user_input):
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ê³ , ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ë©° UIë¥¼ ì—…ë°ì´íŠ¸í•¨.
    ë¦¬í„´ê°’: boolean (reset_triggered ì—¬ë¶€ - ë¦¬í”Œë ‰ì…˜ ë“±ìœ¼ë¡œ ì¸í•œ ì¬ì‹œì‘ í•„ìš” ì‹œ True)
    """
    inputs = {"messages": [HumanMessage(content=user_input)]}
    reset_triggered = False
    
    # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ê¸°ì¡´ ë©”ì‹œì§€ ì •ê·œí™” ì„¸íŠ¸ ìƒì„±
    existing_contents_normalized = set(
        normalize_text(msg["content"]) for msg in st.session_state.messages if msg.get("content")
    )
    
    # ì§ì „ AI ë©”ì‹œì§€ í™•ì¸ (ì—°ì† ì¤‘ë³µ ë°©ì§€)
    last_ai_content_normalized = ""
    for msg in reversed(st.session_state.messages):
        if msg.get("role") == "assistant":
            last_ai_content_normalized = normalize_text(msg.get("content", ""))
            break

    # ê·¸ë˜í”„ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    for event in st.session_state.graph.stream(inputs, st.session_state.config):
        for node, data in event.items():
            
            # [A] í˜‘ìƒê°€(AI) ë…¸ë“œ ì²˜ë¦¬
            if node in ["negotiator"]:
                if "messages" in data and data["messages"]:
                    ai_msg = data["messages"][-1]
                    content = ai_msg.content
                    content_norm = normalize_text(content)

                    # ë‚´ìš©ì´ ì—†ê±°ë‚˜, ì´ë¯¸ ìˆëŠ” ë‚´ìš©ì´ê±°ë‚˜, ì§ì „ ë‚´ìš©ê³¼ ê°™ìœ¼ë©´ ìŠ¤í‚µ
                    if not content or \
                       content_norm in existing_contents_normalized or \
                       (last_ai_content_normalized and content_norm == last_ai_content_normalized):
                        continue

                    if not reset_triggered:
                        with st.chat_message("assistant", avatar="ğŸ¤–"):
                            st.markdown(content)
                    
                    # ì„¸ì…˜ì— ê¸°ë¡
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": content, 
                        "avatar": "ğŸ¤–"
                    })
                    # ì¤‘ë³µ ì²´í¬ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
                    existing_contents_normalized.add(content_norm)

            # [B] í‰ê°€ì(Evaluator) ë…¸ë“œ ì²˜ë¦¬
            elif node == "evaluator":
                result_text = data.get("final_result", "")
                if not reset_triggered:
                    with st.status("âš–ï¸ í˜‘ìƒ í‰ê°€ ì§„í–‰ ì¤‘...", expanded=True) as status:
                        st.write(result_text)
                        score_info = f"êµ¬ë§¤ì ì ìˆ˜: {data.get('buyer_reward')} / íŒë§¤ì ì ìˆ˜: {data.get('seller_reward')}"
                        st.info(score_info)
                        status.update(label="í‰ê°€ ì™„ë£Œ", state="complete")

            # [C] ë°˜ì„±ì(Reflector) ë…¸ë“œ ì²˜ë¦¬ (Reflexion ëª¨ë“œ)
            elif node == "reflector":
                reflections = data.get("reflections", [])
                if reflections:
                    # í˜„ì¬ ìƒíƒœ ìŠ¤ëƒ…ìƒ· ê°€ì ¸ì˜¤ê¸°
                    snapshot = st.session_state.graph.get_state(st.session_state.config)
                    current_reflections = snapshot.values.get("reflections", [])
                    max_retries = snapshot.values.get("max_retries", 3)
                    current_count = len(current_reflections) + 1 # í˜„ì¬ ì‹œì 

                    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì¶”ê°€
                    warning_msg = (f"**[Self-Reflection]** ({current_count}/{max_retries}íšŒ)\n"
                                   "ëª©í‘œ ë‹¬ì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì „ëµì„ ìˆ˜ì •í•˜ì—¬ ë‹¤ì‹œ í˜‘ìƒí•©ë‹ˆë‹¤.")
                    
                    st.session_state.messages = [] # í™”ë©´ í´ë¦¬ì–´
                    st.session_state.messages.append({
                            "role": "system",
                            "content": warning_msg,
                            "avatar": "ğŸ”„"
                    })
                    
                    reset_triggered = True
                    st.toast("ì „ëµ ìˆ˜ì • ì¤‘... ëŒ€í™”ë¥¼ ì¬ì„¤ì •í•©ë‹ˆë‹¤.", icon="ğŸ”„")

    return reset_triggered

def render_sidebar():
    """ì‚¬ì´ë“œë°” ì •ë³´ ë° ì´ˆê¸°í™” ë²„íŠ¼ ë Œë”ë§"""
    with st.sidebar:
        st.subheader("ì‹¤í—˜ ì •ë³´")
        st.write(f"**ëª¨ë“œ:** {st.session_state.mode}")
        st.write(f"**ë‚´ ì—­í• :** {st.session_state.user_role}")
        st.write(f"**ìƒëŒ€ë°©:** {'íŒë§¤ì' if st.session_state.user_role == 'êµ¬ë§¤ì' else 'êµ¬ë§¤ì'}")
        st.write(f"**ëª¨ë¸:** {st.session_state.model_name}")

        st.divider()
        st.subheader("ë‚´ ìš°ì„ ìˆœìœ„")
        user_priorities = PRIORITIES.get(st.session_state.user_role, {})
        for item, score in user_priorities.items():
            st.write(f"- {item} ({score}ì )")
        
        st.divider()
        if st.button("ğŸ”„ ì‹¤í—˜ ë‹¤ì‹œ í•˜ê¸° (ì´ˆê¸°í™”)", type="secondary"):
            st.session_state.is_started = False
            st.session_state.messages = []
            st.rerun()

def render_chat_history():
    """ì €ì¥ëœ ëŒ€í™” ê¸°ë¡ ë Œë”ë§"""
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ (í•­ìƒ ìƒë‹¨ í‘œì‹œ)
    st.chat_message("system", avatar="ğŸ“").write(f"**[SYSTEM]** {st.session_state.mode} ëª¨ë“œë¡œ í˜‘ìƒì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    # ëŒ€í™” ë‚´ìš©
    for msg in st.session_state.messages:
        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ìœ„ì—ì„œ ë”°ë¡œ ì²˜ë¦¬í–ˆê±°ë‚˜, messages ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ë Œë”ë§
        if msg["role"] == "system":
            with st.chat_message("system", avatar="ğŸ”„"): # Reflector ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë“±
                st.markdown(msg["content"])
        else:
            with st.chat_message(msg["role"], avatar=msg.get("avatar")):
                st.markdown(msg["content"])

def check_negotiation_finished():
    """í˜‘ìƒ ì¢…ë£Œ ìƒíƒœ í™•ì¸ ë° ì¶•í•˜ íš¨ê³¼"""
    current_state = st.session_state.graph.get_state(st.session_state.config)
    if current_state.values.get("is_finished") and not current_state.next:
         st.success("ğŸ‰ í˜‘ìƒì´ ìµœì¢… ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
         st.balloons()

def render_chat_screen():
    """ì±„íŒ… í™”ë©´ ì „ì²´ë¥¼ êµ¬ì„±í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    
    # 1. ì‚¬ì´ë“œë°” ë Œë”ë§
    render_sidebar()

    # 2. ëŒ€í™” ê¸°ë¡ ë Œë”ë§ (ì»¨í…Œì´ë„ˆ ì‚¬ìš© ê¶Œì¥)
    chat_container = st.container()
    with chat_container:
        render_chat_history()

    # 3. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        # (1) ì‚¬ìš©ì ë©”ì‹œì§€ ì¦‰ì‹œ í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": prompt, "avatar": "ğŸ‘¤"})
        with chat_container:
            with st.chat_message("user", avatar="ğŸ‘¤"):
                st.markdown(prompt)

        # (2) AI ì‘ë‹µ ì²˜ë¦¬ (ìŠ¤íŠ¸ë¦¬ë°)
        with st.spinner("ìƒëŒ€ë°©ì´ ìƒê° ì¤‘ì…ë‹ˆë‹¤..."):
            # ì—¬ê¸°ì„œ ë³µì¡í•œ ë¡œì§ í•¨ìˆ˜ í˜¸ì¶œ
            should_reset = process_graph_stream(prompt)
            
            if should_reset:
                st.rerun()
        
        # (3) ì¢…ë£Œ ì²´í¬
        check_negotiation_finished()